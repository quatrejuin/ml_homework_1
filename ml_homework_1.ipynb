{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IFT6390 Fundamentals of Machine Learning\n",
    "- Professor: Ioannis Mitliagkas\n",
    "- Homework 1\n",
    "- Students: Jiechen Wu, David"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:05:29.407665Z",
     "start_time": "2018-09-16T16:05:29.404395Z"
    }
   },
   "source": [
    "#  1. Small exercise on probabilities [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few years ago, a study was carried out with doctors in the United States, in order to measure their \"probabilistic intuition\". It included the following question:\n",
    "\n",
    "A percentage of 1.5% of women in their 40s who take a routine test (mammogram) have breast cancer. Among women that have breast cancer, there is a 87% chance that the test is positive. In women that do not have breast cancer, there is a probability of 9.6% that the test is positive.\n",
    "\n",
    "A woman in her forties who has passed this routine test receives a positive test result. What is the probability that it is actually breast cancer?\n",
    "- A) more than 90%\n",
    "- B) between 70% and 90%\n",
    "- C) between 50% and 70%\n",
    "- D) between 30% and 50%\n",
    "- E) between 10% and 30%\n",
    "- F) less than 10%\n",
    "\n",
    "95% of doctors surveyed responded B). What do you think? Formalize the question and calculate the exact probability. Hint: use Bayes rule ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:15:04.022051Z",
     "start_time": "2018-09-16T16:15:04.010317Z"
    }
   },
   "source": [
    "Denote the probability of cancer happening as $p(X=True)$, and\n",
    "denote the probability of test saying the result is positive as $p(T=Positive)$\n",
    "\n",
    "$$p(T = Negative | X=True) = 1 - p(T = Positive | X=True) = 1 - 0.87 = 0.13$$\n",
    "$$p(T = Negative | X=False) = 1 - p(T = Positive | X=False) = 1 - 0.096 = 0.904$$\n",
    "\n",
    "|                 | X= True | X= False |\n",
    "| --------------- | ----------- | ------------ |\n",
    "| T = Positive | 0.87        | 0.096        |\n",
    "| T = Negative | 0.13        | 0.904        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:25:11.308631Z",
     "start_time": "2018-09-16T16:25:11.303111Z"
    }
   },
   "source": [
    "We are required to calculate $p(X=True|T=Positive)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:32:42.414420Z",
     "start_time": "2018-09-16T16:32:42.400771Z"
    }
   },
   "source": [
    "Based on Bayes rule:\n",
    "    $$ \\begin{align*}\n",
    "p( X=True|T=Positive) &=\\frac{p( T=Positive|X\\ =True) p( X=True)}{p( T=Positve)}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(T=Positive) &= \\sum_{x\\in\\{True,False\\}}{p( T=Positve,x)} \\\\\n",
    "&= \\sum_{x\\in\\{True,False\\}}{p( T=Positve|x)p(x)} \\\\\n",
    "&=0.87\\cdot0.015+0.096\\cdot(1-0.015)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug the numbers in:\n",
    "$$ \\begin{align*}\n",
    "p( X=True|Test=Positive) &=\\frac{0.87\\cdot 0.015}{0.87\\cdot0.015+0.096\\cdot(1-0.015)}\\\\\n",
    "&=0.121\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:59:19.904087Z",
     "start_time": "2018-09-16T16:59:19.898364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12127125731809309"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.87*0.015/(0.87*0.015+0.096*(1-0.015))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Curse of dimensionality and geometric intuition in higher dimensions [20 points]\n",
    "\n",
    "#### 1. We consider a hyper-cube in dimension d (this is a generalization of the 2D square and the 3D cube) with side length c (which can be expressed in cm for example). What is the volume V of this hypercube?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "the volume $$V=c^d$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. We deﬁne a random vector X of dimension d (x ∈ $R^d$ ) distributed uniformly within the hypercube (the probability density p(x) = 0 for all x outside the cube). What is the probability density function p(x) for x inside the cube? Indicate which property(ies) of probability densities functions allow you to calculate this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T17:48:40.121269Z",
     "start_time": "2018-09-16T17:48:40.100688Z"
    }
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "the probability density function $$f(x)=\\frac{1}{c^d}$$\n",
    "\n",
    "The area that is covered under the curve that is produced by this density function and the x- axis is always equal to 1, when it is evaluated over the variable’s domain values.\n",
    "$$\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\dots\\int_{-\\infty}^{\\infty}{f(x)dx_1dx_2\\dots dx_d} = 1 $$\n",
    "\n",
    "$$f(x)c^d=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consider the outter shell (border) of the hypercube of width 3% of c (covering the part of the hypercube extending from the faces of the cube and 0.03c inwards). For example, if c = 100cm, the border will be 3cm (left, right, top, etc ...) and will delimit this way a second (inner) hypercube of side 100−3−3 = 94cm. If we generate a point x according to the previously deﬁned probability distribution (by sampling), what is the probability that it falls in the border area? What is the probability that it falls in the smaller hypercube?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "- The volumn of the smaller hypercube = $(0.94c)^d$ = $0.94^dc^d$\n",
    "- The volumn of the outter shell = $c^d - 0.94^dc^d$ = $(1-0.94^d)c^d$\n",
    "\n",
    "So\n",
    "- The probability that it falss in the smaller hypercube = $\\int_{x \\in smaller\\ hypercube}{p(x)dx}$ = $\\int_{0}^{0.94^d}{p(x)dx}$ = $0.94^d$\n",
    "- The probability that it falss in the border area = $\\int_{x \\in border}{p(x)dx}$ = $\\int_{0}^{1-0.94^d}{p(x)dx}$ = $1-0.94^d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Numerically calculate the probability that x will fall in the narrow border for the following values of d: 1, 2, 3, 5, 10, 100, 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T21:28:15.587172Z",
     "start_time": "2018-09-16T21:28:15.581667Z"
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Plug different $d$ in the formular:\n",
    "$$\\int_{x \\in border}{p(x)dx} = 1-0.94^d$$\n",
    "\n",
    "| d    | probability in border |\n",
    "| ---- | --------------------- |\n",
    "| 1    | 0.060                 |\n",
    "| 2    | 0.116                 |\n",
    "| 3    | 0.169                 |\n",
    "| 5    | 0.266                 |\n",
    "| 10   | 0.461                 |\n",
    "| 100  | 0.998                 |\n",
    "| 1000 | 1.000                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T21:41:53.618905Z",
     "start_time": "2018-09-16T21:41:53.613844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability in border:\n",
      "d=\t1, \t\tp=\t0.060\n",
      "d=\t2, \t\tp=\t0.116\n",
      "d=\t3, \t\tp=\t0.169\n",
      "d=\t5, \t\tp=\t0.266\n",
      "d=\t10, \t\tp=\t0.461\n",
      "d=\t100, \t\tp=\t0.998\n",
      "d=\t1000, \t\tp=\t1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability in border:\")\n",
    "for d in [1, 2, 3, 5, 10, 100, 1000]:\n",
    "    print(\"d=\\t{}, \\t\\tp=\\t{:.3f}\".format(d,1-0.94**d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What do you conclude about the distribution of points in higher dimensions, which is contrary to our intuition in smaller dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T21:48:59.412263Z",
     "start_time": "2018-09-16T21:48:59.404081Z"
    }
   },
   "source": [
    "$$\\lim_{d\\rightarrow+\\infty}{1-0.94^d} = 1$$\n",
    "\n",
    "Even the point fall in the border with a small probability in small dimensions, the probability will grow quickly and tend to be 1 in higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parametric Gaussian density estimation, v.s. Parzen window density estimation [35 points]\n",
    "\n",
    "In this question we consider a dataset D = {$x^{(1)} , . . . , x^{(n)}$} with x ∈ $R^d$ .\n",
    "\n",
    "#### 1. Suppose we have trained the parameters of an isotropic Gaussian density function on D (by maximizing the likelihood) in order to estimate the probability density function.\n",
    "\n",
    "##### (a) Name these parameters and indicate their dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "We need to estimate mean vector $\\mu$ and the covariance matrix $\\Sigma$, specifically it's an isotropic Gaussian density function. so $\\Sigma = \\sigma^2 I$.\n",
    "\n",
    "We have to estimate:\n",
    "\n",
    "- mean vector $\\mu \\in R^d$\n",
    "- covariance matrix $\\Sigma \\in R^{d\\times d}$, $\\sigma \\in R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) If we learn these parameters using the principle of maximum likelihood estimation, express the formula which will give us the value of the optimal parameters as a function of the data points in D — indicate only the formula that calculates the result, you are not asked to rederive it (the formulas for the maximum likelihood estimator can be found at the end of slide set number 5 on the Gaussian distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\mu =\\frac{1}{n}\\sum_{i=1}^{n}{x^{(i)}}$$\n",
    "$$\\Sigma = \\frac{1}{n}\\sum_{i=1}^{n}{(x^{(i)}-\\mu)(x^{(i)}-\\mu)^T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) What is the algorithmic complexity of this training method, i.e. of the method calculating these parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- To calculate $\\mu$ we need to go thourgh the $n$ examples over all dimensions $d$. So it's $O(nd)$\n",
    "- To calculate $\\Sigma$ we need to go thourgh the $n$ examples and work out the dot product of two $d$ dimention vectors. So it's $O(nd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) For a test point x, write the function that will give the probability density predicted at point x: $\\hat{\\ p}_{gauss−isotrop}(x)=$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T11:36:27.224428Z",
     "start_time": "2018-09-18T11:36:27.086969Z"
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\hat{\\ p}_{gauss−isotrop}(x)= \\frac{1}{(2\\pi)^{d/2}\\sigma^d}\\exp(-\\frac{(x-\\mu)^T(x-\\mu)}{2\\sigma^2}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e) What is the algorithmic complexity for calculating this prediction at each new point x?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "THe complexity is $O(d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Now consider that one uses Parzen windows with an isotropic Gaussian kernel of width (standard deviation) σ instead, and that these Parzen windows were trained on D.\n",
    "\n",
    "##### (a) Suppose that the user has ﬁxed σ. What does the \"training/learning\" phase of these Parzen windows consist of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "We do nothing for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  (b) For a test point x, write in a single detailed formula (i.e. with exponentials), the function that will give the probability density predicted at point x: $\\hat{\\ p}_{Parzen} (x) =$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\hat{\\ p}_{Parzen} (x) =\\frac{1}{n\\sqrt{2\\pi}\\sigma}\\sum_{i=1}^{n}\\exp(-\\frac{(x-x^{(i)})^2}{2\\sigma^2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) What is the algorithmic complexity for calculating this prediction at each new point x?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The complexity is $O(nd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Capacity/Expressivity\n",
    "\n",
    "##### (a) Which one of these two approaches (parametric Gaussian v.s. Parzen Gaussian kernel) has the highest capacity (in other words, higher expressivity)? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Parzen Gaussian kernel has the highest capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) With which one of these approaches, and in which scenario, are we likely to be over-ﬁtting (i.e. memorizing the noise in our data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "With Parzen Gaussian kerne,we are more likely to be over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) The value σ in Parzen windows is usually treated as a hyperparameter, whereas for parametric Gaussian density estimation it is usually treated as a parameter. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Because we learn the $\\sigma$ from the data when we use parametric Gaussian, but we should fix it before the training in Parzen windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Now consider parametric density estimation with a diagonal Gaussian density function.\n",
    "\n",
    "##### (a) Express the equation of a diagonal Gaussian density in $R^d$ . Specify what are its parameters and their dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean vector $\\mu \\in R^d$\n",
    "- covariance matrix $\\Sigma \\in R^{d\\times d}$, and since it's diagonal, we have \n",
    "\n",
    "$$ \\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sigma ^{2}_{1} &  &  & \\\\\n",
    " & \\sigma ^{2}_{2} &  & \\\\\n",
    " &  & \\ddots  & \\\\\n",
    " &  &  & \\sigma ^{2}_{d}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "in which $\\sigma ^{2}_{1}, \\sigma ^{2}_{2}, \\cdots, \\sigma ^{2}_{d} \\in R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Show that the components of a random vector following a diagonal Gaussian distribution are independent random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Consider the simple case where n = 2,\n",
    "and where the covariance matrix Σ is diagonal, i.e.,\n",
    "\n",
    "$$x=\\ \\begin{bmatrix}\n",
    "x_{1}\\\\\n",
    "x_{2}\n",
    "\\end{bmatrix} \\ \\ \\ \\ \\mu =\\begin{bmatrix}\n",
    "\\mu _{1}\\\\\n",
    "\\mu _{2}\n",
    "\\end{bmatrix} \\ \\ \\ \\ \\Sigma =\\begin{bmatrix}\n",
    "\\sigma ^{2}_{1} & \\\\\n",
    " & \\sigma ^{2}_{2}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "In this case, the diagonal Gaussian distribution has the form,\n",
    "\n",
    "\n",
    "$$\\begin{align}\\begin{array}{l}\n",
    "p( x;\\ \\mu ,\\ \\Sigma ) \\ &=\\frac{1}{2\\pi \\begin{vmatrix}\n",
    "\\sigma ^{2}_{1} & \\\\\n",
    " & \\sigma ^{2}_{2}\n",
    "\\end{vmatrix}^{1/2}}\\exp\\left( -\\frac{1}{2}\\begin{bmatrix}\n",
    "x_{1} -\\mu _{1}\\\\\n",
    "x_{2} -\\mu _{2}\n",
    "\\end{bmatrix}^{T}\\begin{bmatrix}\n",
    "\\sigma ^{2}_{1} & \\\\\n",
    " & \\sigma ^{2}_{2}\n",
    "\\end{bmatrix}^{-1}\\begin{bmatrix}\n",
    "x_{1} -\\mu _{1}\\\\\n",
    "x_{2} -\\mu _{2}\n",
    "\\end{bmatrix}\\right)\\\\\n",
    "&=\\frac{1}{2\\pi \\left( \\sigma ^{2}_{1} \\cdot \\sigma ^{2}_{2} -0\\cdot 0\\right)^{1/2}}\\exp\\left( -\\frac{1}{2}\\begin{bmatrix}\n",
    "x_{1} -\\mu _{1}\\\\\n",
    "x_{2} -\\mu _{2}\n",
    "\\end{bmatrix}^{T}\\begin{bmatrix}\n",
    "\\frac{1}{\\sigma ^{2}_{1}} & \\\\\n",
    " & \\frac{1}{\\sigma ^{2}_{2}}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{1} -\\mu _{1}\\\\\n",
    "x_{2} -\\mu _{2}\n",
    "\\end{bmatrix}\\right)\\\\\n",
    "&=\\frac{1}{2\\pi \\sigma _{1} \\sigma _{2}}\\exp\\left( -\\frac{1}{2}\\begin{bmatrix}\n",
    "x_{1} -\\mu _{1}\\\\\n",
    "x_{2} -\\mu _{2}\n",
    "\\end{bmatrix}^{T}\\begin{bmatrix}\n",
    "\\frac{1}{\\sigma ^{2}_{1}}( x_{1} -\\mu _{1})\\\\\n",
    "\\frac{1}{\\sigma ^{2}_{2}}( x_{2} -\\mu _{2})\n",
    "\\end{bmatrix}\\right)\\\\\n",
    "&=\\frac{1}{2\\pi \\sigma _{1} \\sigma _{2}}\\exp\\left( -\\frac{1}{2\\sigma ^{2}_{1}}( x_{1} -\\mu _{1})^{2} -\\frac{1}{2\\sigma ^{2}_{2}}( x_{2} -\\mu _{2})^{2}\\right)\\\\\n",
    "&=\\frac{1}{\\sqrt{2\\pi } \\sigma _{1}}\\exp\\left( -\\frac{1}{2\\sigma ^{2}_{1}}( x_{1} -\\mu _{1})^{2}\\right) \\cdot \\frac{1}{\\sqrt{2\\pi } \\sigma _{2}}\\exp\\left( -\\frac{1}{2\\sigma ^{2}_{2}}( x_{2} -\\mu _{2})^{2}\\right)\n",
    "\\end{array}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The last equation we recognize to simply be the product of two independent Gaussian densities,\n",
    "one with mean $\\mu_1$ and variance $\\sigma_1^2$, and the other with mean $\\mu_2$ and variance $\\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Using − log p(x) as the loss, write down the equation corresponding to the empirical risk minimization on the training set D (in order to learn the parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "Loss function:\\ L(p(x))= -\\log p(x) =-\\log \\frac{1}{(2\\pi)^{d/2}\\sqrt{\\Sigma}}\\exp(-0.5(x-\\mu)^T\\Sigma^{-1}(x-\\mu)) \\\\\n",
    "Empirical risk:\\ \\hat{\\ R}(p,D) = \\frac{1}{|D|}\\sum_{(x,y)\\in D} L(p(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Solve this equation analytically in order to obtain the optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
